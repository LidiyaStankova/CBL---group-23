{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2a6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ed26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path().resolve().parent\n",
    "onspd_file = project_root / \"data\" / \"onspd-ppd\" / \"ONSPD_FEB_2025_UK.csv\" # onspd csv avaialable on onedrive\n",
    "pp_dir = project_root / \"data\" / \"onspd-ppd\" # download the ppd csvs between 2021-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4566305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pcd', 'pcd2', 'pcds', 'dointr', 'doterm', 'oscty', 'ced', 'oslaua', 'osward', 'parish', 'usertype', 'oseast1m', 'osnrth1m', 'osgrdind', 'oshlthau', 'nhser', 'ctry', 'rgn', 'streg', 'pcon', 'eer', 'teclec', 'ttwa', 'pct', 'itl', 'statsward', 'oa01', 'casward', 'npark', 'lsoa01', 'msoa01', 'ur01ind', 'oac01', 'oa11', 'lsoa11', 'msoa11', 'wz11', 'sicbl', 'bua24', 'ru11ind', 'oac11', 'lat', 'long', 'lep1', 'lep2', 'pfa', 'imd', 'calncv', 'icb', 'oa21', 'lsoa21', 'msoa21']\n"
     ]
    }
   ],
   "source": [
    "tmp = pd.read_csv(onspd_file, nrows=0)\n",
    "print(tmp.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cc37ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pcds\n",
      "0  AB1 0AA\n",
      "1  AB1 0AB\n",
      "2  AB1 0AD\n",
      "3  AB1 0AE\n",
      "4  AB1 0AF\n",
      "5  AB1 0AG\n",
      "6  AB1 0AJ\n",
      "7  AB1 0AL\n",
      "8  AB1 0AN\n",
      "9  AB1 0AP\n"
     ]
    }
   ],
   "source": [
    "tmp_head = pd.read_csv(onspd_file, usecols=[\"pcds\"], nrows=10) # input the name of the column you want to look into\n",
    "print(tmp_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd710fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "onspd_cols = [\n",
    "    \"pcds\", # postcode w/o space\n",
    "    \"lsoa21\",  # 2021 LSOA code\n",
    "    \"pfa\", # police force area code\n",
    "    \"ctry\", # country code (E92000001 = England)\n",
    "    \"rgn\", # region code (E12000007 = London)\n",
    "    \"lat\", # latitude\n",
    "    \"long\", # longitude\n",
    "    \"imd\" # deprivation score\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346a69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onspd = (\n",
    "    pd.read_csv(\n",
    "        onspd_file, \n",
    "        usecols = onspd_cols, \n",
    "        dtype = str\n",
    "    )\n",
    "    .rename(columns = {\n",
    "        \"pcds\":  \"postcode\", \n",
    "        \"lsoa21\": \"LSOA_code\", \n",
    "        \"pfa\": \"police_force_area\", \n",
    "        \"ctry\": \"country_code\", \n",
    "        \"rgn\": \"region_code\", \n",
    "        \"lat\": \"latitude\", \n",
    "        \"long\": \"longitude\", \n",
    "        \"imd\": \"imd_score\"\n",
    "    })\n",
    "    .assign(\n",
    "        postcode = lambda df: (\n",
    "            df.postcode.str.upper().str.replace(r\"\\s+\", \"\", regex = True)\n",
    "        ), \n",
    "        latitude = lambda df: pd.to_numeric(df.latitude, errors = \"coerce\"), \n",
    "        longitude = lambda df: pd.to_numeric(df.longitude, errors = \"coerce\"), \n",
    "        imd_score = lambda df: pd.to_numeric(df.imd_score, errors = \"coerce\")\n",
    "    )\n",
    "    # .query(\"region_code == 'E12000007'\") # London\n",
    "    .drop_duplicates(subset = \"postcode\") # ONSPD is supposed to have one unique postcode per row\n",
    "    .reset_index(drop = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97988651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['postcode', 'country_code', 'region_code', 'latitude', 'longitude', 'police_force_area', 'imd_score', 'LSOA_code']\n"
     ]
    }
   ],
   "source": [
    "print(onspd.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c178e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp-2021.csv ['{D707E535-5720-0AD9-E053-6B04A8C067CC}', '260000', '2021-08-06 00:00', 'SO45 2HT', 'T', 'N', 'F', '17', 'Unnamed: 8', 'PERRYWOOD CLOSE', 'HOLBURY', 'SOUTHAMPTON', 'NEW FOREST', 'HAMPSHIRE', 'A', 'A.1']\n",
      "pp-2022.csv ['{045A1898-4ABF-9A24-E063-4804A8C048EA}', '407400', '2022-04-28 00:00', 'LU7 3FZ', 'S', 'Y', 'F', '68', 'Unnamed: 8', 'RAMSAY DRIVE', 'Unnamed: 10', 'LEIGHTON BUZZARD', 'CENTRAL BEDFORDSHIRE', 'CENTRAL BEDFORDSHIRE.1', 'A', 'A.1']\n",
      "pp-2023.csv ['{0E082197-8499-5C09-E063-4704A8C0A10E}', '440000', '2023-10-12 00:00', 'B16 9BL', 'S', 'N', 'F', '46', 'Unnamed: 8', 'STIRLING ROAD', 'Unnamed: 10', 'BIRMINGHAM', 'BIRMINGHAM.1', 'WEST MIDLANDS', 'B', 'A']\n",
      "pp-2024.csv ['{2F7F2B43-E776-E08F-E063-4804A8C05A49}', '185000', '2024-09-03 00:00', 'E6 1LP', 'F', 'N', 'L', '63A', 'Unnamed: 8', 'STAMFORD ROAD', 'Unnamed: 10', 'LONDON', 'NEWHAM', 'GREATER LONDON', 'B', 'A']\n",
      "pp-2025.csv ['{31C68072-988E-FEE3-E063-4804A8C04F37}', '320000', '2025-02-28 00:00', 'KT20 5SJ', 'F', 'N', 'L', '21', 'Unnamed: 8', 'CORNER FARM CLOSE', 'Unnamed: 10', 'TADWORTH', 'REIGATE AND BANSTEAD', 'SURREY', 'A', 'A.1']\n"
     ]
    }
   ],
   "source": [
    "for path in sorted(pp_dir.glob(\"pp-*.csv\")):\n",
    "    hdrs = pd.read_csv(path, nrows=0).columns.tolist()\n",
    "    print(path.name, hdrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a3e8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_files = sorted(pp_dir.glob(\"pp-202[1-5].csv\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b91d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_cols = [\n",
    "    \"txn_id\",                   # Transaction unique identifier\n",
    "    \"price\",                    # Price\n",
    "    \"date_of_transfer\",         # Date of Transfer\n",
    "    \"postcode\",                 # Postcode\n",
    "    \"property_type\",            # Property Type\n",
    "    \"old_new\",                  # Old / New\n",
    "    \"duration\",                 # Duration\n",
    "    \"paon\",                     # PAON\n",
    "    \"saon\",                     # SAON\n",
    "    \"street\",                   # Street\n",
    "    \"locality\",                 # Locality\n",
    "    \"town_city\",                # Town/City\n",
    "    \"district\",                 # District\n",
    "    \"county\",                   # County\n",
    "    \"ppd_category_type\",        # PPD Category Type\n",
    "    \"record_status\",            # Record Status\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47319b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = [\n",
    "    \"txn_id\", \n",
    "    \"postcode\", \n",
    "    \"price\",\n",
    "    \"property_type\",  \n",
    "    \"old_new\", \n",
    "    \"duration\", \n",
    "    \"ppd_category_type\", \n",
    "    \"record_status\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd917f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_pp(path):\n",
    "    print(f\"Loading: {path.name}\")\n",
    "    df = pd.read_csv(path, header = None, names = pp_cols, dtype=str)\n",
    "    df[\"postcode\"] = (\n",
    "        df[\"postcode\"]\n",
    "        .str.upper()\n",
    "        .str.replace(r\"\\s+\", \"\", regex = True)\n",
    "    )\n",
    "    df = df[wanted]\n",
    "    merged = df.merge(onspd, how = \"left\", on = \"postcode\")\n",
    "    print(f\"{len(merged):,} rows, and \" f\"{merged['LSOA_code'].isna().sum():,} missing LSOAs\")\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6754b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pp-2021.csv', 'pp-2022.csv', 'pp-2023.csv', 'pp-2024.csv', 'pp-2025.csv']\n"
     ]
    }
   ],
   "source": [
    "print([f.name for f in pp_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84036b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: pp-2021.csv\n",
      "1,277,243 rows, and 4,059 missing LSOAs\n",
      "Loading: pp-2022.csv\n",
      "1,068,645 rows, and 3,055 missing LSOAs\n",
      "Loading: pp-2023.csv\n",
      "845,990 rows, and 2,284 missing LSOAs\n",
      "Loading: pp-2024.csv\n",
      "737,255 rows, and 1,596 missing LSOAs\n",
      "Loading: pp-2025.csv\n",
      "106,006 rows, and 97 missing LSOAs\n"
     ]
    }
   ],
   "source": [
    "all_pp = pd.concat(\n",
    "    (load_and_merge_pp(fp) for fp in pp_files),\n",
    "    ignore_index = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c417741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['txn_id', 'postcode', 'price', 'property_type', 'old_new', 'duration', 'ppd_category_type', 'record_status', 'country_code', 'region_code', 'latitude', 'longitude', 'police_force_area', 'imd_score', 'LSOA_code']\n"
     ]
    }
   ],
   "source": [
    "print(all_pp.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f52f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "txn_id                   0\n",
       "LSOA_code            11091\n",
       "police_force_area    11091\n",
       "imd_score            11088\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pp[[\"txn_id\", \"LSOA_code\", \"police_force_area\", \"imd_score\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a830d748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11091"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pp[\"LSOA_code\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc578ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pp = all_pp.dropna(subset=[\"LSOA_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69fbddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 4,024,048 rows missing → 0.00%\n",
      "Unique unmatched postcodes: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 1a) How many rows & what percent\n",
    "n = len(all_pp)\n",
    "missing = all_pp[\"LSOA_code\"].isna().sum()\n",
    "print(f\"{missing:,} / {n:,} rows missing → {missing/n:.2%}\")\n",
    "\n",
    "# 1b) Which postcodes didn’t match?\n",
    "bad = all_pp.loc[all_pp[\"LSOA_code\"].isna(), \"postcode\"]\n",
    "print(\"Unique unmatched postcodes:\", bad.nunique())\n",
    "print(bad.unique()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a714c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   n_missing  pct_missing\n",
      "txn_id                     0          0.0\n",
      "postcode                   0          0.0\n",
      "price                      0          0.0\n",
      "property_type              0          0.0\n",
      "old_new                    0          0.0\n",
      "duration                   0          0.0\n",
      "ppd_category_type          0          0.0\n",
      "record_status              0          0.0\n",
      "country_code               0          0.0\n",
      "region_code                0          0.0\n",
      "latitude                   0          0.0\n",
      "longitude                  0          0.0\n",
      "police_force_area          0          0.0\n",
      "imd_score                  0          0.0\n",
      "LSOA_code                  0          0.0\n"
     ]
    }
   ],
   "source": [
    "missing_df = (\n",
    "    all_pp.isna().sum()\n",
    "      .rename(\"n_missing\")\n",
    "      .to_frame()\n",
    "      .assign(\n",
    "         pct_missing = lambda df: (df[\"n_missing\"] / len(all_pp) * 100).round(2)\n",
    "      )\n",
    "      .sort_values(\"pct_missing\", ascending = False)\n",
    ")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "055490d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pp = all_pp.drop_duplicates(subset = \"txn_id\", keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64e0aca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,024,048 rows before dropping duplicates\n"
     ]
    }
   ],
   "source": [
    "before = len(all_pp)\n",
    "print(f\"{before:,} rows before dropping duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae2d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 4,024,048 dropped 0 rows\n"
     ]
    }
   ],
   "source": [
    "all_pp = all_pp.query(\"record_status == 'A'\") # only keeps the rows that satisfy the boolean condition\n",
    "after = len(all_pp)\n",
    "print(f\"Kept {after:,}\", f\"dropped {before - after:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8505e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "required = [\n",
    "    \"postcode\", \n",
    "    \"country_code\", \n",
    "    \"region_code\", \n",
    "    \"latitude\", \n",
    "    \"longitude\", \n",
    "    \"police_force_area\", \n",
    "    \"imd_score\", \n",
    "    \"LSOA_code\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ae78946",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pp_london = all_pp.query(\"region_code == 'E12000007'\") # London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c15c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows are completely blank in all 8 columns.\n"
     ]
    }
   ],
   "source": [
    "all_missing = all_pp_london[required].isna().all(axis = 1).sum()\n",
    "print(f\"{all_missing:,} rows are completely blank in all {len(required)} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eb7b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows are missing at least one of those columns.\n"
     ]
    }
   ],
   "source": [
    "any_missing = all_pp_london[required].isna().any(axis = 1).sum()\n",
    "print(f\"{any_missing:,} rows are missing at least one of those columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90019828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows by how many of the required columns are missing:\n",
      "_count\n",
      "0    451737\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pattern = (\n",
    "    all_pp_london[required]\n",
    "      .isna()\n",
    "      .astype(int)\n",
    "      .assign(_count = lambda df: df.sum(axis = 1))\n",
    "      ._count\n",
    "      .value_counts()\n",
    "      .sort_index()\n",
    ")\n",
    "print(\"Number of rows by how many of the required columns are missing:\")\n",
    "print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "868f6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_count = all_pp_london[required].isna().sum(axis = 1)\n",
    "clean_pp = all_pp_london.loc[miss_count <= 6].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52403ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Dropped {(miss_count >= 7).sum():,} rows missing 7–8 fields, \"\n",
    "    f\"kept {len(clean_pp):,} rows.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c67958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   n_missing  pct_missing\n",
      "postcode                   0          0.0\n",
      "country_code               0          0.0\n",
      "region_code                0          0.0\n",
      "latitude                   0          0.0\n",
      "longitude                  0          0.0\n",
      "police_force_area          0          0.0\n",
      "imd_score                  0          0.0\n",
      "LSOA_code                  0          0.0\n"
     ]
    }
   ],
   "source": [
    "missing_df = (\n",
    "    clean_pp.isna().sum()\n",
    "      .rename(\"n_missing\")\n",
    "      .to_frame()\n",
    "      .assign(\n",
    "         pct_missing = lambda df: (df[\"n_missing\"] / len(clean_pp) * 100).round(2)\n",
    "      )\n",
    "      .loc[required]\n",
    ")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2610ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# 1) Build a KD‐tree of all ONSPD postcodes that have LSOA, region, police, etc.\n",
    "geo = onspd[[\"postcode\", \"latitude\", \"longitude\", \"LSOA_code\", \"region_code\", \"police_force_area\"]].dropna()\n",
    "coords = geo[[\"latitude\", \"longitude\"]].values # index on latitude & longitude\n",
    "tree = cKDTree(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Mask the 3 rows in clean_pp that still need imputation:\n",
    "mask = clean_pp[required].isna().any(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e688ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Query the nearest known point for each of those rows\n",
    "query_pts = clean_pp.loc[mask, [\"latitude\", \"longitude\"]].values\n",
    "_, idxs = tree.query(query_pts, k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Grab the metadata from geo at those indices\n",
    "nearest = geo.iloc[idxs].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"LSOA_code\", \"region_code\", \"police_force_area\"]:\n",
    "    clean_pp.loc[mask, col] = nearest[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_pp[required].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f982ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "processed = project_root / \"data\" / \"clean-pp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35cfccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da18351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fp = processed / \"clean_pp.csv\"\n",
    "parquet_fp = processed / \"clean_pp.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09ee4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pp.to_csv(csv_fp, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b3ead6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pp.to_parquet(parquet_fp, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
